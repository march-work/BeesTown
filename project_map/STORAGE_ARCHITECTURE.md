# BeesTown å­˜å‚¨æ¶æ„è®¾è®¡

## 1. æ¦‚è¿°

BeesTown é‡‡ç”¨**åˆ†å±‚å­˜å‚¨æ¶æ„**ï¼Œç»“åˆå‘é‡æ•°æ®åº“ï¼ˆçŸ­æœŸè®°å¿†ï¼‰å’Œ SQLiteï¼ˆé•¿æœŸè®°å¿†/ç»“æ„åŒ–æ•°æ®ï¼‰ï¼Œå®ç°é«˜æ•ˆçš„è®°å¿†æ£€ç´¢å’Œæ•°æ®æŒä¹…åŒ–ã€‚

```mermaid
graph TB
    subgraph StorageLayer["å­˜å‚¨å±‚æ¶æ„"]
        direction TB
        
        subgraph STM["çŸ­æœŸè®°å¿†å±‚ (Short-Term Memory)"]
            VectorDB["ğŸ§  å‘é‡æ•°æ®åº“<br/>ChromaDB / Pinecone<br/>-------------------<br/>â€¢ è¯­ä¹‰æ£€ç´¢<br/>â€¢ ç›¸ä¼¼åº¦æœç´¢<br/>â€¢ ä¼šè¯ä¸Šä¸‹æ–‡"]
        end

        subgraph LTM["é•¿æœŸè®°å¿†å±‚ (Long-Term Memory)"]
            SQLite["ğŸ’¾ SQLite<br/>ç»“æ„åŒ–æ•°æ®å­˜å‚¨<br/>-------------------<br/>â€¢ é¡¹ç›®é…ç½®<br/>â€¢ Agentä¿¡æ¯<br/>â€¢ å†å²è®°å½•<br/>â€¢ ä½¿ç”¨ç»Ÿè®¡"]
        end

        subgraph Cache["ç¼“å­˜å±‚"]
            MemoryCache["âš¡ å†…å­˜ç¼“å­˜<br/>LRU Cache<br/>-------------------<br/>â€¢ çƒ­æ•°æ®ç¼“å­˜<br/>â€¢ ä¼šè¯çŠ¶æ€<br/>â€¢ é¢‘ç¹è®¿é—®æ•°æ®"]
        end
    end

    subgraph DataTypes["æ•°æ®ç±»å‹åˆ†å¸ƒ"]
        direction TB
        
        VectorData["å‘é‡æ•°æ®<br/>â€¢ æ–‡æœ¬åµŒå…¥<br/>â€¢ è¯­ä¹‰å‘é‡<br/>â€¢ ç›¸ä¼¼åº¦ç´¢å¼•"]
        
        StructuredData["ç»“æ„åŒ–æ•°æ®<br/>â€¢ é¡¹ç›®å…ƒæ•°æ®<br/>â€¢ Agenté…ç½®<br/>â€¢ ä»»åŠ¡è®°å½•<br/>â€¢ Tokenä½¿ç”¨"]
        
        BlobData["å¤§å¯¹è±¡æ•°æ®<br/>â€¢ æ–‡ä»¶å†…å®¹<br/>â€¢ ä»£ç å¿«ç…§<br/>â€¢ æ—¥å¿—æ–‡ä»¶"]
    end

    STM --> VectorData
    LTM --> StructuredData
    LTM --> BlobData
    Cache --> STM
    Cache --> LTM
```

---

## 2. çŸ­æœŸè®°å¿†å­˜å‚¨ï¼ˆå‘é‡æ•°æ®åº“ï¼‰

### 2.1 æŠ€æœ¯é€‰å‹

| ç‰¹æ€§ | æ–¹æ¡ˆ | è¯´æ˜ |
|------|------|------|
| é»˜è®¤æ–¹æ¡ˆ | **ChromaDB** | æœ¬åœ°åµŒå…¥å¼ï¼Œæ— éœ€å¤–éƒ¨æœåŠ¡ |
| äº‘ç«¯æ–¹æ¡ˆ | Pinecone | å¤§è§„æ¨¡é¡¹ç›®ï¼Œéœ€è¦API Key |
| æ··åˆæ–¹æ¡ˆ | ChromaDB + å¯é€‰Pinecone | æœ¬åœ°ä¼˜å…ˆï¼Œäº‘ç«¯æ‰©å±• |

### 2.2 æ•°æ®æ¨¡å‹

```typescript
// å‘é‡é›†åˆå®šä¹‰
interface VectorCollections {
  // ä¼šè¯ä¸Šä¸‹æ–‡é›†åˆ
  session_context: {
    id: string;                    // å”¯ä¸€æ ‡è¯†
    projectId: string;             // æ‰€å±é¡¹ç›®
    agentId: string;               // æ‰€å±Agent
    sessionId: string;             // ä¼šè¯ID
    content: string;               // åŸå§‹å†…å®¹
    embedding: number[];           // å‘é‡åµŒå…¥ (1536ç»´)
    metadata: {
      timestamp: number;           // æ—¶é—´æˆ³
      type: 'thought' | 'action' | 'observation' | 'conversation';
      importance: number;          // é‡è¦æ€§è¯„åˆ† (0-1)
      relatedFiles?: string[];     // ç›¸å…³æ–‡ä»¶
      relatedAgents?: string[];    // ç›¸å…³Agent
    };
  };

  // ä»£ç è¯­ä¹‰é›†åˆ
  code_semantics: {
    id: string;
    projectId: string;
    filePath: string;              // æ–‡ä»¶è·¯å¾„
    content: string;               // ä»£ç å†…å®¹/æ‘˜è¦
    embedding: number[];
    metadata: {
      language: string;            // ç¼–ç¨‹è¯­è¨€
      symbols: string[];           // å®šä¹‰çš„ç¬¦å·
      dependencies: string[];      // ä¾èµ–æ–‡ä»¶
      lastModified: number;        // æœ€åä¿®æ”¹æ—¶é—´
    };
  };

  // çŸ¥è¯†ç‰‡æ®µé›†åˆ
  knowledge_snippets: {
    id: string;
    projectId: string;
    content: string;               // çŸ¥è¯†å†…å®¹
    embedding: number[];
    metadata: {
      category: string;            // çŸ¥è¯†ç±»åˆ«
      source: string;              // æ¥æº
      confidence: number;          // å¯ä¿¡åº¦
      usageCount: number;          // ä½¿ç”¨æ¬¡æ•°
    };
  };
}
```

### 2.3 å­˜å‚¨ç­–ç•¥

```typescript
class ShortTermMemoryStore {
  private client: ChromaClient;
  private embeddingFunction: OpenAIEmbeddingFunction;

  constructor(config: VectorDBConfig) {
    this.client = new ChromaClient({ path: config.path });
    this.embeddingFunction = new OpenAIEmbeddingFunction({
      apiKey: config.apiKey,
      model: 'text-embedding-3-small'
    });
  }

  // å­˜å‚¨è®°å¿†ç‰‡æ®µ
  async store(memory: MemoryFragment): Promise<void> {
    const collection = await this.getCollection(memory.type);
    
    // ç”ŸæˆåµŒå…¥å‘é‡
    const embedding = await this.embeddingFunction.generate(memory.content);
    
    // å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
    await collection.add({
      ids: [memory.id],
      embeddings: [embedding],
      documents: [memory.content],
      metadatas: [memory.metadata]
    });

    // åŒæ­¥åˆ°é•¿æœŸè®°å¿†ï¼ˆå¦‚æœé‡è¦æ€§é«˜ï¼‰
    if (memory.metadata.importance > 0.7) {
      await this.archiveToLongTerm(memory);
    }
  }

  // è¯­ä¹‰æ£€ç´¢
  async retrieve(query: string, options: RetrieveOptions): Promise<MemoryFragment[]> {
    const collection = await this.getCollection(options.type);
    
    // ç”ŸæˆæŸ¥è¯¢å‘é‡
    const queryEmbedding = await this.embeddingFunction.generate(query);
    
    // å‘é‡ç›¸ä¼¼åº¦æœç´¢
    const results = await collection.query({
      queryEmbeddings: [queryEmbedding],
      nResults: options.limit || 10,
      where: options.filter,
      include: ['documents', 'metadatas', 'distances']
    });

    return this.formatResults(results);
  }

  // æ—¶é—´çª—å£æ£€ç´¢ï¼ˆè·å–æœ€è¿‘Næ¡ï¼‰
  async retrieveRecent(agentId: string, limit: number = 50): Promise<MemoryFragment[]> {
    const collection = await this.getCollection('session_context');
    
    return await collection.get({
      where: { agentId },
      limit,
      sort: { timestamp: 'desc' }
    });
  }

  // æ¸…ç†è¿‡æœŸçŸ­æœŸè®°å¿†
  async cleanup(maxAge: number = 7 * 24 * 60 * 60 * 1000): Promise<void> {
    const cutoffTime = Date.now() - maxAge;
    
    for (const collection of this.collections) {
      const oldMemories = await collection.get({
        where: { 
          timestamp: { $lt: cutoffTime },
          importance: { $lt: 0.5 }  // åªåˆ é™¤ä¸é‡è¦çš„
        }
      });

      // å½’æ¡£é‡è¦è®°å¿†ååˆ é™¤
      for (const memory of oldMemories) {
        if (memory.metadata.importance > 0.3) {
          await this.archiveToLongTerm(memory);
        }
        await collection.delete({ ids: [memory.id] });
      }
    }
  }
}
```

### 2.4 è®°å¿†ç”Ÿå‘½å‘¨æœŸ

```mermaid
graph LR
    A["æ–°è®°å¿†äº§ç”Ÿ"] --> B{"é‡è¦æ€§è¯„ä¼°"}
    B -->|é«˜é‡è¦æ€§ (>0.7)| C["ç«‹å³å½’æ¡£åˆ°é•¿æœŸè®°å¿†"]
    B -->|ä¸­ç­‰é‡è¦æ€§| D["çŸ­æœŸè®°å¿†å­˜å‚¨"]
    D --> E{"7å¤©å"}
    E -->|é‡è¦æ€§>0.3| F["å½’æ¡£åˆ°é•¿æœŸè®°å¿†"]
    E -->|é‡è¦æ€§<0.3| G["åˆ é™¤"]
    C --> H["é•¿æœŸè®°å¿† SQLite"]
    F --> H
```

---

## 3. é•¿æœŸè®°å¿†å­˜å‚¨ï¼ˆSQLiteï¼‰

### 3.1 æ•°æ®åº“è®¾è®¡

```sql
-- é¡¹ç›®è¡¨
CREATE TABLE projects (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    description TEXT,
    created_at INTEGER NOT NULL,
    updated_at INTEGER NOT NULL,
    status TEXT CHECK(status IN ('active', 'paused', 'archived')),
    config_json TEXT  -- JSONæ ¼å¼å­˜å‚¨é¡¹ç›®é…ç½®
);

-- Agentè¡¨
CREATE TABLE agents (
    id TEXT PRIMARY KEY,
    project_id TEXT NOT NULL,
    name TEXT NOT NULL,
    role TEXT NOT NULL,
    department_id TEXT,
    level INTEGER NOT NULL,
    reports_to TEXT,
    state_json TEXT NOT NULL,  -- AgentçŠ¶æ€
    performance_json TEXT,     -- ç»©æ•ˆæ•°æ®
    created_at INTEGER NOT NULL,
    FOREIGN KEY (project_id) REFERENCES projects(id),
    FOREIGN KEY (reports_to) REFERENCES agents(id)
);

-- éƒ¨é—¨è¡¨
CREATE TABLE departments (
    id TEXT PRIMARY KEY,
    project_id TEXT NOT NULL,
    name TEXT NOT NULL,
    code TEXT NOT NULL,
    level INTEGER NOT NULL,
    parent_id TEXT,
    head_id TEXT,
    shared_resources_json TEXT,  -- å…±äº«èµ„æºé…ç½®
    FOREIGN KEY (project_id) REFERENCES projects(id),
    FOREIGN KEY (head_id) REFERENCES agents(id)
);

-- é•¿æœŸè®°å¿†è¡¨
CREATE TABLE long_term_memories (
    id TEXT PRIMARY KEY,
    project_id TEXT NOT NULL,
    agent_id TEXT,
    department_id TEXT,
    memory_type TEXT NOT NULL CHECK(memory_type IN ('personal', 'department', 'company', 'hr')),
    category TEXT NOT NULL,  -- è®°å¿†ç±»åˆ«
    content TEXT NOT NULL,
    summary TEXT,            -- å†…å®¹æ‘˜è¦
    keywords TEXT,           -- å…³é”®è¯ï¼Œé€—å·åˆ†éš”
    importance REAL NOT NULL,
    access_count INTEGER DEFAULT 0,
    last_accessed INTEGER,
    created_at INTEGER NOT NULL,
    vector_id TEXT,          -- å…³è”çš„å‘é‡ID
    FOREIGN KEY (project_id) REFERENCES projects(id),
    FOREIGN KEY (agent_id) REFERENCES agents(id)
);

-- ä»»åŠ¡è¡¨
CREATE TABLE tasks (
    id TEXT PRIMARY KEY,
    project_id TEXT NOT NULL,
    title TEXT NOT NULL,
    description TEXT,
    assignee_id TEXT,
    creator_id TEXT NOT NULL,
    parent_task_id TEXT,
    status TEXT CHECK(status IN ('pending', 'in_progress', 'reviewing', 'completed', 'cancelled')),
    priority INTEGER DEFAULT 3,
    started_at INTEGER,
    completed_at INTEGER,
    estimated_hours INTEGER,
    actual_hours INTEGER,
    result_json TEXT,        -- ä»»åŠ¡ç»“æœ
    FOREIGN KEY (project_id) REFERENCES projects(id),
    FOREIGN KEY (assignee_id) REFERENCES agents(id)
);

-- Tokenä½¿ç”¨ç»Ÿè®¡è¡¨
CREATE TABLE token_usage (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    project_id TEXT NOT NULL,
    agent_id TEXT NOT NULL,
    session_id TEXT NOT NULL,
    timestamp INTEGER NOT NULL,
    model TEXT NOT NULL,
    input_tokens INTEGER NOT NULL,
    output_tokens INTEGER NOT NULL,
    total_tokens INTEGER NOT NULL,
    cost_usd REAL,
    request_type TEXT,       -- 'chat', 'embedding', 'tool_call'
    task_id TEXT,
    FOREIGN KEY (project_id) REFERENCES projects(id),
    FOREIGN KEY (agent_id) REFERENCES agents(id)
);

-- Agentå·¥ä½œæ—¶é—´ç»Ÿè®¡è¡¨
CREATE TABLE agent_work_stats (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    agent_id TEXT NOT NULL,
    date TEXT NOT NULL,      -- YYYY-MM-DD
    project_id TEXT NOT NULL,
    tasks_completed INTEGER DEFAULT 0,
    tasks_created INTEGER DEFAULT 0,
    messages_sent INTEGER DEFAULT 0,
    messages_received INTEGER DEFAULT 0,
    work_minutes INTEGER DEFAULT 0,
    idle_minutes INTEGER DEFAULT 0,
    token_input_total INTEGER DEFAULT 0,
    token_output_total INTEGER DEFAULT 0,
    UNIQUE(agent_id, date)
);

-- æ–‡ä»¶æ“ä½œæ—¥å¿—è¡¨
CREATE TABLE file_operations (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    project_id TEXT NOT NULL,
    agent_id TEXT NOT NULL,
    timestamp INTEGER NOT NULL,
    operation TEXT NOT NULL CHECK(operation IN ('read', 'write', 'edit', 'delete', 'create', 'search')),
    file_path TEXT NOT NULL,
    content_hash TEXT,       -- å†…å®¹å“ˆå¸Œï¼Œç”¨äºç‰ˆæœ¬æ§åˆ¶
    diff_patch TEXT,         -- å˜æ›´è¡¥ä¸ï¼ˆå¦‚æœæ˜¯ç¼–è¾‘ï¼‰
    success BOOLEAN NOT NULL,
    error_message TEXT
);

-- Agenté€šä¿¡è®°å½•è¡¨
CREATE TABLE agent_communications (
    id TEXT PRIMARY KEY,
    project_id TEXT NOT NULL,
    sender_id TEXT NOT NULL,
    receiver_id TEXT NOT NULL,
    message_type TEXT CHECK(message_type IN ('direct', 'broadcast', 'task_assignment', 'report')),
    content TEXT NOT NULL,
    context_json TEXT,       -- é€šä¿¡ä¸Šä¸‹æ–‡
    timestamp INTEGER NOT NULL,
    read_at INTEGER,
    related_task_id TEXT
);

-- ä»£ç æ¶æ„ç´¢å¼•è¡¨ï¼ˆæ¶æ„å¸ˆAgentç»´æŠ¤ï¼‰
CREATE TABLE code_architecture (
    id TEXT PRIMARY KEY,
    project_id TEXT NOT NULL,
    file_path TEXT NOT NULL,
    file_type TEXT NOT NULL,
    purpose TEXT,            -- æ–‡ä»¶ç”¨é€”æè¿°
    functions_json TEXT,     -- å‡½æ•°/ç±»åˆ—è¡¨
    dependencies TEXT,       -- ä¾èµ–æ–‡ä»¶ï¼ŒJSONæ•°ç»„
    dependents TEXT,         -- è¢«ä¾èµ–æ–‡ä»¶ï¼ŒJSONæ•°ç»„
    test_files TEXT,         -- å…³è”æµ‹è¯•æ–‡ä»¶
    last_analyzed INTEGER,
    architecture_version INTEGER DEFAULT 1
);

-- ç´¢å¼•ä¼˜åŒ–
CREATE INDEX idx_agents_project ON agents(project_id);
CREATE INDEX idx_agents_department ON agents(department_id);
CREATE INDEX idx_memories_project ON long_term_memories(project_id);
CREATE INDEX idx_memories_agent ON long_term_memories(agent_id);
CREATE INDEX idx_memories_type ON long_term_memories(memory_type);
CREATE INDEX idx_token_usage_project ON token_usage(project_id, timestamp);
CREATE INDEX idx_token_usage_agent ON token_usage(agent_id, timestamp);
CREATE INDEX idx_file_ops_project ON file_operations(project_id, file_path);
CREATE INDEX idx_communications_project ON agent_communications(project_id, timestamp);
```

### 3.2 æ•°æ®è®¿é—®å±‚

```typescript
class LongTermMemoryStore {
  private db: Database;

  constructor(dbPath: string) {
    this.db = new Database(dbPath);
    this.initTables();
  }

  // ==================== é¡¹ç›®æ“ä½œ ====================
  
  async createProject(project: Project): Promise<void> {
    const stmt = this.db.prepare(`
      INSERT INTO projects (id, name, description, created_at, updated_at, status, config_json)
      VALUES (?, ?, ?, ?, ?, ?, ?)
    `);
    
    stmt.run(
      project.id,
      project.name,
      project.description,
      Date.now(),
      Date.now(),
      'active',
      JSON.stringify(project.config)
    );
  }

  // ==================== Agentæ“ä½œ ====================

  async createAgent(agent: Agent): Promise<void> {
    const stmt = this.db.prepare(`
      INSERT INTO agents (id, project_id, name, role, department_id, level, reports_to, state_json, created_at)
      VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
    `);

    stmt.run(
      agent.id,
      agent.projectId,
      agent.name,
      agent.role,
      agent.departmentId,
      agent.level,
      agent.reportsTo,
      JSON.stringify(agent.state),
      Date.now()
    );
  }

  async updateAgentState(agentId: string, state: Partial<AgentState>): Promise<void> {
    const current = await this.getAgent(agentId);
    const newState = { ...JSON.parse(current.state_json), ...state };
    
    const stmt = this.db.prepare(`
      UPDATE agents SET state_json = ?, updated_at = ? WHERE id = ?
    `);
    
    stmt.run(JSON.stringify(newState), Date.now(), agentId);
  }

  // ==================== é•¿æœŸè®°å¿†æ“ä½œ ====================

  async storeLongTermMemory(memory: LongTermMemory): Promise<void> {
    const stmt = this.db.prepare(`
      INSERT INTO long_term_memories 
      (id, project_id, agent_id, department_id, memory_type, category, content, summary, keywords, importance, created_at)
      VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    `);

    const summary = await this.generateSummary(memory.content);
    const keywords = await this.extractKeywords(memory.content);

    stmt.run(
      memory.id,
      memory.projectId,
      memory.agentId,
      memory.departmentId,
      memory.memoryType,
      memory.category,
      memory.content,
      summary,
      keywords.join(','),
      memory.importance,
      Date.now()
    );
  }

  async retrieveLongTermMemories(options: RetrieveOptions): Promise<LongTermMemory[]> {
    let query = `
      SELECT * FROM long_term_memories 
      WHERE project_id = ?
    `;
    const params: any[] = [options.projectId];

    if (options.agentId) {
      query += ' AND agent_id = ?';
      params.push(options.agentId);
    }

    if (options.memoryType) {
      query += ' AND memory_type = ?';
      params.push(options.memoryType);
    }

    if (options.category) {
      query += ' AND category = ?';
      params.push(options.category);
    }

    if (options.keywords?.length) {
      const keywordConditions = options.keywords.map(() => 'keywords LIKE ?').join(' OR ');
      query += ` AND (${keywordConditions})`;
      params.push(...options.keywords.map(k => `%${k}%`));
    }

    query += ' ORDER BY importance DESC, created_at DESC';

    if (options.limit) {
      query += ' LIMIT ?';
      params.push(options.limit);
    }

    return this.db.prepare(query).all(...params);
  }

  // ==================== Tokenä½¿ç”¨ç»Ÿè®¡ ====================

  async recordTokenUsage(usage: TokenUsage): Promise<void> {
    const stmt = this.db.prepare(`
      INSERT INTO token_usage 
      (project_id, agent_id, session_id, timestamp, model, input_tokens, output_tokens, total_tokens, cost_usd, request_type, task_id)
      VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    `);

    const cost = this.calculateCost(usage.model, usage.inputTokens, usage.outputTokens);

    stmt.run(
      usage.projectId,
      usage.agentId,
      usage.sessionId,
      Date.now(),
      usage.model,
      usage.inputTokens,
      usage.outputTokens,
      usage.inputTokens + usage.outputTokens,
      cost,
      usage.requestType,
      usage.taskId
    );

    // æ›´æ–°å·¥ä½œç»Ÿè®¡
    await this.updateWorkStats(usage.agentId, usage.projectId, usage);
  }

  async getTokenUsageStats(options: StatsOptions): Promise<TokenStats> {
    const query = `
      SELECT 
        SUM(input_tokens) as total_input,
        SUM(output_tokens) as total_output,
        SUM(total_tokens) as total_tokens,
        SUM(cost_usd) as total_cost,
        COUNT(*) as request_count,
        model
      FROM token_usage
      WHERE project_id = ? AND timestamp BETWEEN ? AND ?
      ${options.agentId ? 'AND agent_id = ?' : ''}
      GROUP BY model
    `;

    const params = [options.projectId, options.startTime, options.endTime];
    if (options.agentId) params.push(options.agentId);

    return this.db.prepare(query).all(...params);
  }

  // ==================== Agentå·¥ä½œç»Ÿè®¡ ====================

  async updateWorkStats(agentId: string, projectId: string, usage: TokenUsage): Promise<void> {
    const date = new Date().toISOString().split('T')[0];
    
    const stmt = this.db.prepare(`
      INSERT INTO agent_work_stats 
      (agent_id, date, project_id, token_input_total, token_output_total)
      VALUES (?, ?, ?, ?, ?)
      ON CONFLICT(agent_id, date) DO UPDATE SET
        token_input_total = token_input_total + excluded.token_input_total,
        token_output_total = token_output_total + excluded.token_output_total
    `);

    stmt.run(agentId, date, projectId, usage.inputTokens, usage.outputTokens);
  }

  async getAgentWorkStats(agentId: string, days: number = 30): Promise<WorkStats[]> {
    const query = `
      SELECT * FROM agent_work_stats
      WHERE agent_id = ? AND date >= date('now', '-${days} days')
      ORDER BY date DESC
    `;

    return this.db.prepare(query).all(agentId);
  }

  // ==================== æ–‡ä»¶æ“ä½œæ—¥å¿— ====================

  async logFileOperation(operation: FileOperation): Promise<void> {
    const stmt = this.db.prepare(`
      INSERT INTO file_operations
      (project_id, agent_id, timestamp, operation, file_path, content_hash, diff_patch, success, error_message)
      VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
    `);

    stmt.run(
      operation.projectId,
      operation.agentId,
      Date.now(),
      operation.operation,
      operation.filePath,
      operation.contentHash,
      operation.diffPatch,
      operation.success,
      operation.errorMessage
    );
  }

  async getFileHistory(projectId: string, filePath: string): Promise<FileOperation[]> {
    const query = `
      SELECT * FROM file_operations
      WHERE project_id = ? AND file_path = ?
      ORDER BY timestamp DESC
    `;

    return this.db.prepare(query).all(projectId, filePath);
  }

  // ==================== ä»£ç æ¶æ„ç´¢å¼• ====================

  async updateCodeArchitecture(arch: CodeArchitecture): Promise<void> {
    const stmt = this.db.prepare(`
      INSERT INTO code_architecture
      (id, project_id, file_path, file_type, purpose, functions_json, dependencies, dependents, test_files, last_analyzed, architecture_version)
      VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
      ON CONFLICT(id) DO UPDATE SET
        purpose = excluded.purpose,
        functions_json = excluded.functions_json,
        dependencies = excluded.dependencies,
        dependents = excluded.dependents,
        test_files = excluded.test_files,
        last_analyzed = excluded.last_analyzed,
        architecture_version = architecture_version + 1
    `);

    stmt.run(
      arch.id,
      arch.projectId,
      arch.filePath,
      arch.fileType,
      arch.purpose,
      JSON.stringify(arch.functions),
      JSON.stringify(arch.dependencies),
      JSON.stringify(arch.dependents),
      JSON.stringify(arch.testFiles),
      Date.now(),
      1
    );
  }

  // ==================== è¾…åŠ©æ–¹æ³• ====================

  private async generateSummary(content: string): Promise<string> {
    // ä½¿ç”¨LLMæˆ–è§„åˆ™ç”Ÿæˆæ‘˜è¦
    if (content.length < 200) return content;
    return content.substring(0, 200) + '...';
  }

  private async extractKeywords(content: string): Promise<string[]> {
    // ç®€å•çš„å…³é”®è¯æå–ï¼Œå®é™…å¯ç”¨NLPåº“
    const words = content.toLowerCase().split(/\s+/);
    const stopWords = new Set(['the', 'a', 'an', 'is', 'are', 'was', 'were']);
    return words.filter(w => w.length > 3 && !stopWords.has(w)).slice(0, 10);
  }

  private calculateCost(model: string, inputTokens: number, outputTokens: number): number {
    const pricing: Record<string, { input: number; output: number }> = {
      'gpt-4': { input: 0.03, output: 0.06 },
      'gpt-4-turbo': { input: 0.01, output: 0.03 },
      'gpt-3.5-turbo': { input: 0.0005, output: 0.0015 }
    };

    const price = pricing[model] || pricing['gpt-3.5-turbo'];
    return (inputTokens * price.input + outputTokens * price.output) / 1000;
  }
}
```

---

## 4. ç¼“å­˜å±‚è®¾è®¡

### 4.1 å†…å­˜ç¼“å­˜

```typescript
class MemoryCache {
  private cache: Map<string, CacheEntry>;
  private maxSize: number;
  private ttl: number;

  constructor(maxSize: number = 1000, ttl: number = 5 * 60 * 1000) {
    this.cache = new Map();
    this.maxSize = maxSize;
    this.ttl = ttl;
  }

  get<T>(key: string): T | undefined {
    const entry = this.cache.get(key);
    
    if (!entry) return undefined;
    
    if (Date.now() - entry.timestamp > this.ttl) {
      this.cache.delete(key);
      return undefined;
    }

    entry.accessCount++;
    return entry.value as T;
  }

  set<T>(key: string, value: T): void {
    if (this.cache.size >= this.maxSize) {
      this.evictLRU();
    }

    this.cache.set(key, {
      value,
      timestamp: Date.now(),
      accessCount: 1
    });
  }

  private evictLRU(): void {
    let oldestKey: string | null = null;
    let oldestTime = Infinity;

    for (const [key, entry] of this.cache.entries()) {
      if (entry.timestamp < oldestTime) {
        oldestTime = entry.timestamp;
        oldestKey = key;
      }
    }

    if (oldestKey) {
      this.cache.delete(oldestKey);
    }
  }

  invalidate(pattern: RegExp): void {
    for (const key of this.cache.keys()) {
      if (pattern.test(key)) {
        this.cache.delete(key);
      }
    }
  }
}
```

---

## 5. ç»Ÿä¸€å­˜å‚¨æ¥å£

```typescript
class BeesTownStorage {
  private shortTerm: ShortTermMemoryStore;
  private longTerm: LongTermMemoryStore;
  private cache: MemoryCache;

  constructor(config: StorageConfig) {
    this.shortTerm = new ShortTermMemoryStore(config.vectorDB);
    this.longTerm = new LongTermMemoryStore(config.sqlitePath);
    this.cache = new MemoryCache();
  }

  // æ™ºèƒ½å­˜å‚¨ï¼šè‡ªåŠ¨å†³å®šå­˜å‚¨ä½ç½®
  async store(data: MemoryData): Promise<void> {
    // è¯„ä¼°é‡è¦æ€§
    const importance = await this.assessImportance(data);

    if (importance > 0.7) {
      // é«˜é‡è¦æ€§ï¼šåŒæ—¶å­˜å‚¨åˆ°çŸ­æœŸå’Œé•¿æœŸ
      await Promise.all([
        this.shortTerm.store({ ...data, metadata: { ...data.metadata, importance } }),
        this.longTerm.storeLongTermMemory({ ...data, importance })
      ]);
    } else {
      // ä½é‡è¦æ€§ï¼šä»…çŸ­æœŸå­˜å‚¨
      await this.shortTerm.store({ ...data, metadata: { ...data.metadata, importance } });
    }
  }

  // æ™ºèƒ½æ£€ç´¢ï¼šå¤šæºèšåˆ
  async retrieve(query: string, options: RetrieveOptions): Promise<RetrievalResult[]> {
    const cacheKey = `retrieve:${query}:${JSON.stringify(options)}`;
    const cached = this.cache.get<RetrievalResult[]>(cacheKey);
    if (cached) return cached;

    // å¹¶è¡Œæ£€ç´¢çŸ­æœŸå’Œé•¿æœŸè®°å¿†
    const [shortTermResults, longTermResults] = await Promise.all([
      this.shortTerm.retrieve(query, options),
      this.longTerm.retrieveLongTermMemories(options)
    ]);

    // åˆå¹¶å’Œæ’åºç»“æœ
    const merged = this.mergeResults(shortTermResults, longTermResults);
    
    this.cache.set(cacheKey, merged);
    return merged;
  }

  // è·å–Agentå®Œæ•´è®°å¿†ä¸Šä¸‹æ–‡
  async getAgentContext(agentId: string, projectId: string): Promise<AgentContext> {
    const [recentMemories, longTermMemories, workStats] = await Promise.all([
      this.shortTerm.retrieveRecent(agentId, 50),
      this.longTerm.retrieveLongTermMemories({
        projectId,
        agentId,
        limit: 20
      }),
      this.longTerm.getAgentWorkStats(agentId, 7)
    ]);

    return {
      shortTerm: recentMemories,
      longTerm: longTermMemories,
      workStats,
      summary: this.generateContextSummary(recentMemories, longTermMemories)
    };
  }

  // è®°å½•Tokenä½¿ç”¨
  async recordTokenUsage(usage: TokenUsage): Promise<void> {
    await this.longTerm.recordTokenUsage(usage);
  }

  // è·å–é¡¹ç›®ç»Ÿè®¡
  async getProjectStats(projectId: string): Promise<ProjectStats> {
    const cacheKey = `stats:${projectId}`;
    const cached = this.cache.get<ProjectStats>(cacheKey);
    if (cached) return cached;

    const stats = await this.longTerm.getProjectStats(projectId);
    this.cache.set(cacheKey, stats);
    return stats;
  }

  private async assessImportance(data: MemoryData): Promise<number> {
    // åŸºäºå†…å®¹ç‰¹å¾è¯„ä¼°é‡è¦æ€§
    let score = 0.5;

    // åŒ…å«å…³é”®å†³ç­–è¯æ±‡
    if (/decision|conclusion|agreed|approved/i.test(data.content)) score += 0.2;
    
    // åŒ…å«é”™è¯¯/å¼‚å¸¸
    if (/error|exception|failed|bug/i.test(data.content)) score += 0.15;
    
    // é•¿åº¦å› ç´ 
    if (data.content.length > 500) score += 0.1;

    // ç”¨æˆ·æ˜ç¡®æ ‡è®°
    if (data.metadata?.importance) score = data.metadata.importance;

    return Math.min(score, 1.0);
  }

  private mergeResults(shortTerm: any[], longTerm: any[]): RetrievalResult[] {
    // åˆå¹¶å¹¶å»é‡
    const seen = new Set<string>();
    const merged: RetrievalResult[] = [];

    for (const item of [...shortTerm, ...longTerm]) {
      const key = item.id || item.content?.substring(0, 100);
      if (!seen.has(key)) {
        seen.add(key);
        merged.push({
          source: item.vector_id ? 'short_term' : 'long_term',
          content: item.content || item.document,
          relevance: item.distance || item.importance,
          metadata: item.metadata
        });
      }
    }

    return merged.sort((a, b) => b.relevance - a.relevance);
  }
}
```

---

## 6. æ•°æ®è¿ç§»ä¸å¤‡ä»½

```typescript
class StorageMigration {
  // ä»çŸ­æœŸè®°å¿†å½’æ¡£åˆ°é•¿æœŸè®°å¿†
  async archiveOldMemories(ageDays: number = 7): Promise<void> {
    const cutoff = Date.now() - ageDays * 24 * 60 * 60 * 1000;
    
    const oldMemories = await this.shortTerm.getMemoriesBefore(cutoff);
    
    for (const memory of oldMemories) {
      if (memory.metadata.importance > 0.3) {
        await this.longTerm.storeLongTermMemory({
          ...memory,
          vectorId: memory.id
        });
      }
      
      await this.shortTerm.delete(memory.id);
    }
  }

  // é¡¹ç›®å¤‡ä»½
  async backupProject(projectId: string, backupPath: string): Promise<void> {
    const data = {
      project: await this.longTerm.getProject(projectId),
      agents: await this.longTerm.getProjectAgents(projectId),
      departments: await this.longTerm.getProjectDepartments(projectId),
      memories: await this.longTerm.retrieveLongTermMemories({ projectId, limit: 10000 }),
      timestamp: Date.now()
    };

    await fs.writeFile(
      path.join(backupPath, `${projectId}_backup_${Date.now()}.json`),
      JSON.stringify(data, null, 2)
    );
  }

  // é¡¹ç›®æ¢å¤
  async restoreProject(backupPath: string): Promise<void> {
    const data = JSON.parse(await fs.readFile(backupPath, 'utf-8'));
    
    await this.longTerm.createProject(data.project);
    
    for (const agent of data.agents) {
      await this.longTerm.createAgent(agent);
    }
    
    for (const memory of data.memories) {
      await this.longTerm.storeLongTermMemory(memory);
    }
  }
}
```

---

## 7. æ€§èƒ½ä¼˜åŒ–

### 7.1 æŸ¥è¯¢ä¼˜åŒ–

```typescript
// ç´¢å¼•ç­–ç•¥
const INDEXES = [
  'CREATE INDEX IF NOT EXISTS idx_memories_search ON long_term_memories(project_id, memory_type, category)',
  'CREATE INDEX IF NOT EXISTS idx_token_time ON token_usage(project_id, agent_id, timestamp)',
  'CREATE INDEX IF NOT EXISTS idx_files_path ON file_operations(project_id, file_path, timestamp)'
];

// æ‰¹é‡æ“ä½œ
class BatchOperations {
  private batch: any[] = [];
  private maxBatchSize = 100;

  async add(operation: any): Promise<void> {
    this.batch.push(operation);
    
    if (this.batch.length >= this.maxBatchSize) {
      await this.flush();
    }
  }

  async flush(): Promise<void> {
    if (this.batch.length === 0) return;

    const transaction = this.db.transaction(() => {
      for (const op of this.batch) {
        op.execute();
      }
    });

    transaction();
    this.batch = [];
  }
}
```

### 7.2 å­˜å‚¨é…é¢ç®¡ç†

```typescript
class StorageQuota {
  private limits = {
    maxVectorMemories: 100000,    // æœ€å¤§å‘é‡è®°å¿†æ•°
    maxDailyTokens: 10000000,     // æ¯æ—¥æœ€å¤§Tokenæ•°
    maxFileHistory: 1000,         // æ¯æ–‡ä»¶æœ€å¤§å†å²è®°å½•
    maxProjectAge: 365            // é¡¹ç›®æœ€å¤§ä¿ç•™å¤©æ•°
  };

  async enforceQuota(projectId: string): Promise<void> {
    // æ¸…ç†è¿‡æœŸå‘é‡è®°å¿†
    await this.shortTerm.cleanup();
    
    // å½’æ¡£æ—§æ–‡ä»¶å†å²
    await this.archiveOldFileOperations(projectId);
    
    // å‹ç¼©é•¿æœŸè®°å¿†
    await this.compressLongTermMemories(projectId);
  }
}
```

---

## 8. æ€»ç»“

BeesTown å­˜å‚¨æ¶æ„çš„æ ¸å¿ƒè®¾è®¡ï¼š

1. **åˆ†å±‚å­˜å‚¨**ï¼šå‘é‡æ•°æ®åº“ï¼ˆçŸ­æœŸï¼‰+ SQLiteï¼ˆé•¿æœŸï¼‰
2. **æ™ºèƒ½å½’æ¡£**ï¼šåŸºäºé‡è¦æ€§è‡ªåŠ¨å†³å®šå­˜å‚¨ä½ç½®
3. **ç»Ÿä¸€æ¥å£**ï¼šå¯¹å¤–æä¾›ç®€æ´çš„å­˜å‚¨/æ£€ç´¢API
4. **å®Œæ•´ç»Ÿè®¡**ï¼šTokenä½¿ç”¨ã€å·¥ä½œæ—¶é—´ã€æ–‡ä»¶æ“ä½œå…¨è®°å½•
5. **æ€§èƒ½ä¼˜åŒ–**ï¼šç¼“å­˜ã€ç´¢å¼•ã€æ‰¹é‡æ“ä½œ
6. **æ•°æ®å®‰å…¨**ï¼šå¤‡ä»½ã€æ¢å¤ã€é…é¢ç®¡ç†
